{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.13.0 # torchtext.legacy 라이브러리를 불러오기 위해 torch 다시 install\n",
        "!pip install -U torchtext==0.11.0 #torchtext install"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ude2B_MfN67e",
        "outputId": "156fdbf3-d5ff-4182-a77d-34e0c93780e1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch==1.13.0\n",
            "  Downloading torch-1.13.0-cp38-cp38-manylinux1_x86_64.whl (890.2 MB)\n",
            "\u001b[K     |█████▉                          | 161.1 MB 1.3 MB/s eta 0:09:01\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
            "\u001b[?25hLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchtext==0.11.0 in /usr/local/lib/python3.8/dist-packages (0.11.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchtext==0.11.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torchtext==0.11.0) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchtext==0.11.0) (1.21.6)\n",
            "Requirement already satisfied: torch==1.10.0 in /usr/local/lib/python3.8/dist-packages (from torchtext==0.11.0) (1.10.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.10.0->torchtext==0.11.0) (4.4.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.11.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.11.0) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.11.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.11.0) (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqoEcHmr2yxP"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchtext.legacy import data, datasets \n",
        "from google.colab import drive\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# for reproducibility\n",
        "torch.manual_seed(777)\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed_all(777)\n",
        "\n",
        "# parameters\n",
        "batch_size = 64\n",
        "learning_rate = 0.0001\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT = data.Field(sequential=True, batch_first=True, lower=True)\n",
        "LABEL = data.Field(sequential=False, batch_first=True)\n",
        "trainset, validset, testset = datasets.SST.splits(TEXT, LABEL)\n",
        "\n",
        "TEXT.build_vocab(trainset, min_freq=5)\n",
        "LABEL.build_vocab(trainset)\n",
        "\n",
        "#이미 valid가 나뉘어져 있어서 따로 나누지 않음\n",
        "train_iter, val_iter, test_iter = data.BucketIterator.splits(\n",
        "        (trainset, validset, testset), batch_size=batch_size,\n",
        "        shuffle=True, repeat=False)\n",
        "\n",
        "vocab_size = len(TEXT.vocab)\n",
        "n_classes = 3 # Positive, Negative Class가 두 개인데 SST는 3개\n",
        "\n",
        "print(\"[TrainSet]: %d [ValSet]: %d [TestSet]: %d [Vocab]: %d [Classes] %d\"\n",
        "      % (len(trainset),len(validset), len(testset), vocab_size, n_classes))"
      ],
      "metadata": {
        "id": "w24445CHhyfX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7683c4bd-8c23-4396-f45c-7f408641683b"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TrainSet]: 8544 [ValSet]: 1101 [TestSet]: 2210 [Vocab]: 3428 [Classes] 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicGRU(nn.Module):\n",
        "    def __init__(self, n_layers, hidden_dim, n_vocab, embed_dim, n_classes, dropout_p=0.2):\n",
        "        super(BasicGRU, self).__init__()\n",
        "        self.n_layers = n_layers # 일반적으로는 2\n",
        "\n",
        "        self.embed = nn.Embedding(n_vocab, embed_dim)\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "        self.gru = nn.GRU(embed_dim, self.hidden_dim,\n",
        "                          num_layers=self.n_layers,\n",
        "                          batch_first=True)\n",
        "        \n",
        "        self.out = nn.Linear(self.hidden_dim, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embed(x)\n",
        "        x, _ = self.gru(x)\n",
        "\n",
        "        h_t = x[:,-1,:]\n",
        "\n",
        "        self.dropout(h_t)\n",
        "\n",
        "        out = self.out(h_t)\n",
        "        return out"
      ],
      "metadata": {
        "id": "zsvpOb8giPxE"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss().to(device)    # Softmax\n",
        "batchs_size = [32,64,128] # 변경할 batch\n",
        "learning_rate = [0.0005, 0.0001, 0.00005] # 변경할 learning rate\n",
        "total_best = -1 # 전체 중에 가장 정확도가 높은\n",
        "for ba in batchs_size:\n",
        "    train_iter.batchs_= ba\n",
        "    for lr in learning_rate:\n",
        "        model = BasicGRU(1, 256, vocab_size, 128, n_classes, 0.5).to(device)\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "        count = 0\n",
        "        best = -1 # 현재 돌리는 batch, learning rate 중에 가장 정확도가 높은\n",
        "        total_epoch = 0\n",
        "        epoch = 0\n",
        "\n",
        "        while count != 3: # count가 3번 그대로일 때 \n",
        "            epoch = 0\n",
        "            avg_cost = 0\n",
        "            for epoch in range(2): #2번씩 돌아가고 validset을 이용해 accuracy를 측정\n",
        "              total_epoch+=1\n",
        "              model.train()\n",
        "              for batch in train_iter:\n",
        "                  X, Y = batch.text.to(device), batch.label.to(device)\n",
        "                  Y.data.sub_(1)\n",
        "                  optimizer.zero_grad()\n",
        "                  hypothesis = model(X)\n",
        "                  cost = criterion(hypothesis, Y)\n",
        "                  cost.backward()\n",
        "                  optimizer.step()\n",
        "                  avg_cost += cost / len(train_iter)\n",
        "                \n",
        "            with torch.no_grad():\n",
        "              corrects = 0\n",
        "              model.eval()\n",
        "              for batch in val_iter:\n",
        "                x,y = batch.text.to(device), batch.label.to(device)\n",
        "                y.data.sub_(1)\n",
        "                hypothesis = model(x)\n",
        "                corrects += (hypothesis.max(1)[1].view(y.size()).data == y.data).sum()\n",
        "\n",
        "            eval_acc = corrects/len(val_iter.dataset)*100.0\n",
        "\n",
        "            if best < eval_acc: # 현재 batch, learning rate에서 가장 높은 모델 정확도 기억\n",
        "              best = eval_acc\n",
        "            else:\n",
        "              count += 1 # 정확도가 높지 않으면 count 증가 (count가 3이되면 학습 종료 후 다음 batch, learning_rate로 넘어감)\n",
        "            print(f'[Epoch: {total_epoch}] train_cost = {avg_cost:>.5} eval_acc = {eval_acc:>.5} best = {best:>.5}')\n",
        "\n",
        "            if total_best<eval_acc:\n",
        "              total_best = eval_acc\n",
        "              torch.save(model.state_dict(), '/model_s1.pt') # 전체중에 가장 높은 모델 model_s1에 저장              \n",
        "              \n",
        "\n",
        "        print(f'{count}번동안 accuracy 증가가 없어 {total_epoch}epcoh 학습 후 종료합니다.\\n')\n"
      ],
      "metadata": {
        "id": "BMLH6xfviUTU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df532c89-c57d-464b-8768-4f29e4c3a68e"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch: 2] train_cost = 2.1021 eval_acc = 45.141 best = 45.141\n",
            "[Epoch: 4] train_cost = 1.8561 eval_acc = 55.767 best = 55.767\n",
            "[Epoch: 6] train_cost = 1.5231 eval_acc = 59.128 best = 59.128\n",
            "[Epoch: 8] train_cost = 1.2074 eval_acc = 57.766 best = 59.128\n",
            "[Epoch: 10] train_cost = 0.89937 eval_acc = 57.493 best = 59.128\n",
            "[Epoch: 12] train_cost = 0.62754 eval_acc = 53.951 best = 59.128\n",
            "3번동안 accuracy 증가가 없어 12epcoh 학습 후 종료합니다.\n",
            "\n",
            "[Epoch: 2] train_cost = 2.103 eval_acc = 39.782 best = 39.782\n",
            "[Epoch: 4] train_cost = 2.099 eval_acc = 41.417 best = 41.417\n",
            "[Epoch: 6] train_cost = 2.0953 eval_acc = 39.782 best = 41.417\n",
            "[Epoch: 8] train_cost = 2.0843 eval_acc = 42.507 best = 42.507\n",
            "[Epoch: 10] train_cost = 1.9953 eval_acc = 52.861 best = 52.861\n",
            "[Epoch: 12] train_cost = 1.8415 eval_acc = 53.86 best = 53.86\n",
            "[Epoch: 14] train_cost = 1.7186 eval_acc = 53.678 best = 53.86\n",
            "[Epoch: 16] train_cost = 1.6065 eval_acc = 56.403 best = 56.403\n",
            "[Epoch: 18] train_cost = 1.4804 eval_acc = 56.131 best = 56.403\n",
            "3번동안 accuracy 증가가 없어 18epcoh 학습 후 종료합니다.\n",
            "\n",
            "[Epoch: 2] train_cost = 2.102 eval_acc = 38.147 best = 38.147\n",
            "[Epoch: 4] train_cost = 2.0954 eval_acc = 40.054 best = 40.054\n",
            "[Epoch: 6] train_cost = 2.095 eval_acc = 40.236 best = 40.236\n",
            "[Epoch: 8] train_cost = 2.0956 eval_acc = 40.145 best = 40.236\n",
            "[Epoch: 10] train_cost = 2.0951 eval_acc = 40.69 best = 40.69\n",
            "[Epoch: 12] train_cost = 2.0921 eval_acc = 40.327 best = 40.69\n",
            "[Epoch: 14] train_cost = 2.0911 eval_acc = 40.327 best = 40.69\n",
            "3번동안 accuracy 증가가 없어 14epcoh 학습 후 종료합니다.\n",
            "\n",
            "[Epoch: 2] train_cost = 2.1099 eval_acc = 39.419 best = 39.419\n",
            "[Epoch: 4] train_cost = 1.9993 eval_acc = 55.767 best = 55.767\n",
            "[Epoch: 6] train_cost = 1.6347 eval_acc = 57.675 best = 57.675\n",
            "[Epoch: 8] train_cost = 1.2959 eval_acc = 55.223 best = 57.675\n",
            "[Epoch: 10] train_cost = 0.94876 eval_acc = 54.587 best = 57.675\n",
            "[Epoch: 12] train_cost = 0.62452 eval_acc = 51.953 best = 57.675\n",
            "3번동안 accuracy 증가가 없어 12epcoh 학습 후 종료합니다.\n",
            "\n",
            "[Epoch: 2] train_cost = 2.1012 eval_acc = 39.419 best = 39.419\n",
            "[Epoch: 4] train_cost = 2.0987 eval_acc = 39.419 best = 39.419\n",
            "[Epoch: 6] train_cost = 2.0952 eval_acc = 39.873 best = 39.873\n",
            "[Epoch: 8] train_cost = 2.0933 eval_acc = 40.327 best = 40.327\n",
            "[Epoch: 10] train_cost = 2.079 eval_acc = 42.416 best = 42.416\n",
            "[Epoch: 12] train_cost = 1.9872 eval_acc = 49.5 best = 49.5\n",
            "[Epoch: 14] train_cost = 1.8307 eval_acc = 52.77 best = 52.77\n",
            "[Epoch: 16] train_cost = 1.691 eval_acc = 54.587 best = 54.587\n",
            "[Epoch: 18] train_cost = 1.5489 eval_acc = 54.496 best = 54.587\n",
            "[Epoch: 20] train_cost = 1.4039 eval_acc = 53.406 best = 54.587\n",
            "3번동안 accuracy 증가가 없어 20epcoh 학습 후 종료합니다.\n",
            "\n",
            "[Epoch: 2] train_cost = 2.0996 eval_acc = 38.874 best = 38.874\n",
            "[Epoch: 4] train_cost = 2.0966 eval_acc = 41.326 best = 41.326\n",
            "[Epoch: 6] train_cost = 2.0959 eval_acc = 40.509 best = 41.326\n",
            "[Epoch: 8] train_cost = 2.0954 eval_acc = 39.964 best = 41.326\n",
            "[Epoch: 10] train_cost = 2.095 eval_acc = 39.873 best = 41.326\n",
            "3번동안 accuracy 증가가 없어 10epcoh 학습 후 종료합니다.\n",
            "\n",
            "[Epoch: 2] train_cost = 2.1112 eval_acc = 40.963 best = 40.963\n",
            "[Epoch: 4] train_cost = 2.032 eval_acc = 55.313 best = 55.313\n",
            "[Epoch: 6] train_cost = 1.6914 eval_acc = 58.674 best = 58.674\n",
            "[Epoch: 8] train_cost = 1.3252 eval_acc = 57.675 best = 58.674\n",
            "[Epoch: 10] train_cost = 0.96014 eval_acc = 56.131 best = 58.674\n",
            "[Epoch: 12] train_cost = 0.60782 eval_acc = 58.038 best = 58.674\n",
            "3번동안 accuracy 증가가 없어 12epcoh 학습 후 종료합니다.\n",
            "\n",
            "[Epoch: 2] train_cost = 2.1038 eval_acc = 43.778 best = 43.778\n",
            "[Epoch: 4] train_cost = 2.0974 eval_acc = 40.327 best = 43.778\n",
            "[Epoch: 6] train_cost = 2.096 eval_acc = 40.145 best = 43.778\n",
            "[Epoch: 8] train_cost = 2.0844 eval_acc = 43.233 best = 43.778\n",
            "3번동안 accuracy 증가가 없어 8epcoh 학습 후 종료합니다.\n",
            "\n",
            "[Epoch: 2] train_cost = 2.107 eval_acc = 39.419 best = 39.419\n",
            "[Epoch: 4] train_cost = 2.0964 eval_acc = 40.145 best = 40.145\n",
            "[Epoch: 6] train_cost = 2.0948 eval_acc = 41.417 best = 41.417\n",
            "[Epoch: 8] train_cost = 2.0955 eval_acc = 41.054 best = 41.417\n",
            "[Epoch: 10] train_cost = 2.095 eval_acc = 40.509 best = 41.417\n",
            "[Epoch: 12] train_cost = 2.0942 eval_acc = 40.418 best = 41.417\n",
            "3번동안 accuracy 증가가 없어 12epcoh 학습 후 종료합니다.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = BasicGRU(1, 256, vocab_size, 128, n_classes, 0.5).to(device)\n",
        "model.load_state_dict(torch.load('/model_s1.pt')) # 가장 정확도가 높았던 모델 불러오기\n",
        "\n",
        "corrects = 0\n",
        "model.eval()\n",
        "for batch in test_iter:\n",
        "    x,y = batch.text.to(device), batch.label.to(device)\n",
        "    y.data.sub_(1)\n",
        "    hypothesis = model(x)\n",
        "    corrects += (hypothesis.max(1)[1].view(y.size()).data == y.data).sum()\n",
        "\n",
        "test_acc = corrects/len(test_iter.dataset)*100.0\n",
        "print(f'test_acc = {test_acc:>.9}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "An6gDl8Owa3J",
        "outputId": "20ae9fe7-b8f5-4d77-d233-a857a216f87b"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_acc = 61.1764717\n"
          ]
        }
      ]
    }
  ]
}