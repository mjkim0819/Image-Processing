{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.13.0 # torchtext.legacy 라이브러리를 불러오기 위해 torch 다시 install\n",
        "!pip install -U torchtext==0.11.0 #torchtext install"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ude2B_MfN67e",
        "outputId": "156fdbf3-d5ff-4182-a77d-34e0c93780e1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch==1.13.0\n",
            "  Downloading torch-1.13.0-cp38-cp38-manylinux1_x86_64.whl (890.2 MB)\n",
            "\u001b[K     |█████▉                          | 161.1 MB 1.3 MB/s eta 0:09:01\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
            "\u001b[?25hLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchtext==0.11.0 in /usr/local/lib/python3.8/dist-packages (0.11.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchtext==0.11.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torchtext==0.11.0) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchtext==0.11.0) (1.21.6)\n",
            "Requirement already satisfied: torch==1.10.0 in /usr/local/lib/python3.8/dist-packages (from torchtext==0.11.0) (1.10.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.10.0->torchtext==0.11.0) (4.4.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.11.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.11.0) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.11.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.11.0) (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqoEcHmr2yxP"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchtext.legacy import data, datasets \n",
        "from google.colab import drive\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# for reproducibility\n",
        "torch.manual_seed(777)\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed_all(777)\n",
        "\n",
        "# parameters\n",
        "batch_size = 64\n",
        "learning_rate = 0.0001\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT = data.Field(sequential=True, batch_first=True, lower=True)\n",
        "LABEL = data.Field(sequential=False, batch_first=True)\n",
        "trainset, validset, testset = datasets.SST.splits(TEXT, LABEL)\n",
        "\n",
        "TEXT.build_vocab(trainset, min_freq=5)\n",
        "LABEL.build_vocab(trainset)\n",
        "\n",
        "#이미 valid가 나뉘어져 있어서 따로 나누지 않음\n",
        "train_iter, val_iter, test_iter = data.BucketIterator.splits(\n",
        "        (trainset, validset, testset), batch_size=batch_size,\n",
        "        shuffle=True, repeat=False)\n",
        "\n",
        "vocab_size = len(TEXT.vocab)\n",
        "n_classes = 3 # Positive, Negative Class가 두 개인데 SST는 3개\n",
        "\n",
        "print(\"[TrainSet]: %d [ValSet]: %d [TestSet]: %d [Vocab]: %d [Classes] %d\"\n",
        "      % (len(trainset),len(validset), len(testset), vocab_size, n_classes))"
      ],
      "metadata": {
        "id": "w24445CHhyfX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53a57327-9e82-45eb-c405-ba8f770e4c53"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TrainSet]: 8544 [ValSet]: 1101 [TestSet]: 2210 [Vocab]: 3428 [Classes] 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicGRU(nn.Module):\n",
        "    def __init__(self, n_layers, hidden_dim, n_vocab, embed_dim, n_classes, dropout_p=0.2):\n",
        "        super(BasicGRU, self).__init__()\n",
        "        self.n_layers = n_layers # 일반적으로는 2\n",
        "\n",
        "        self.embed = nn.Embedding(n_vocab, embed_dim)\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "        self.gru = nn.GRU(embed_dim, self.hidden_dim,\n",
        "                          num_layers=self.n_layers,\n",
        "                          batch_first=True)\n",
        "        \n",
        "        self.out = nn.Linear(self.hidden_dim, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embed(x)\n",
        "        x, _ = self.gru(x)\n",
        "\n",
        "        h_t = x[:,-1,:]\n",
        "\n",
        "        self.dropout(h_t)\n",
        "\n",
        "        out = self.out(h_t)\n",
        "        return out"
      ],
      "metadata": {
        "id": "zsvpOb8giPxE"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss().to(device)    # Softmax\n",
        "batchs_size = [32,64,128] # 변경할 batch\n",
        "learning_rate = [0.0005, 0.0001, 0.00005] # 변경할 learning rate\n",
        "total_best = -1 # 전체 중에 가장 정확도가 높은\n",
        "for ba in batchs_size:\n",
        "    train_iter.batchs_= ba\n",
        "    for lr in learning_rate:\n",
        "        model = BasicGRU(1, 256, vocab_size, 128, n_classes, 0.5).to(device)\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "        count = 0\n",
        "        best = -1 # 현재 돌리는 batch, learning rate 중에 가장 정확도가 높은\n",
        "        total_epoch = 0\n",
        "        epoch = 0\n",
        "\n",
        "        while count != 3: # count가 3번 그대로일 때 \n",
        "            total_epoch+=2\n",
        "            epoch = 0\n",
        "            for epoch in range(2): #2번씩 돌아가고 validset을 이용해 accuracy를 측정\n",
        "              avg_cost = 0\n",
        "              model.train()\n",
        "              for batch in train_iter:\n",
        "                  X, Y = batch.text.to(device), batch.label.to(device)\n",
        "                  Y.data.sub_(1)\n",
        "                  optimizer.zero_grad()\n",
        "                  hypothesis = model(X)\n",
        "                  cost = criterion(hypothesis, Y)\n",
        "                  cost.backward()\n",
        "                  optimizer.step()\n",
        "                  avg_cost += cost / len(train_iter)\n",
        "                \n",
        "              with torch.no_grad():\n",
        "                  corrects = 0\n",
        "                  model.eval()\n",
        "                  for batch in val_iter:\n",
        "                      x,y = batch.text.to(device), batch.label.to(device)\n",
        "                      y.data.sub_(1)\n",
        "                      hypothesis = model(x)\n",
        "                      corrects += (hypothesis.max(1)[1].view(y.size()).data == y.data).sum()\n",
        "\n",
        "                  eval_acc = corrects/len(val_iter.dataset)*100.0\n",
        "\n",
        "            if total_best<eval_acc:\n",
        "              total_best = eval_acc\n",
        "              torch.save(model.state_dict(), '/model_s1.pt') # 전체중에 가장 높은 모델 model_s1에 저장\n",
        "\n",
        "            if best < eval_acc: # 현재 batch, learning rate에서 가장 높은 모델 정확도 기억\n",
        "              best = eval_acc\n",
        "            else:\n",
        "              count += 1 # 정확도가 높지 않으면 count 증가 (count가 3이되면 학습 종료 후 다음 batch, learning_rate로 넘어감)\n",
        "\n",
        "            print(f'[Epoch: {total_epoch}] train_cost = {avg_cost:>.5} eval_acc = {eval_acc:>.5} total_best = {best:>.5}')  \n",
        "              \n",
        "\n",
        "        print(f'{count}번동안 accuracy 증가가 없어 {total_epoch}epcoh 학습 후 종료합니다.\\n')\n"
      ],
      "metadata": {
        "id": "BMLH6xfviUTU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "121bf581-d56b-41b3-cf15-4c48a5ba0bee"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch: 2] train_cost = 1.0498 eval_acc = 39.782 total_best = 39.782\n",
            "[Epoch: 4] train_cost = 0.93291 eval_acc = 53.769 total_best = 53.769\n",
            "[Epoch: 6] train_cost = 0.77501 eval_acc = 57.856 total_best = 57.856\n",
            "[Epoch: 8] train_cost = 0.61426 eval_acc = 56.312 total_best = 57.856\n",
            "[Epoch: 10] train_cost = 0.43626 eval_acc = 56.312 total_best = 57.856\n",
            "[Epoch: 12] train_cost = 0.2671 eval_acc = 55.223 total_best = 57.856\n",
            "3번동안 accuracy 증가가 없어 12epcoh 학습 후 종료합니다.\n",
            "\n",
            "[Epoch: 2] train_cost = 1.0495 eval_acc = 39.328 total_best = 39.328\n",
            "[Epoch: 4] train_cost = 1.0488 eval_acc = 40.054 total_best = 40.054\n",
            "[Epoch: 6] train_cost = 1.0479 eval_acc = 40.872 total_best = 40.872\n",
            "[Epoch: 8] train_cost = 1.0411 eval_acc = 40.418 total_best = 40.872\n",
            "[Epoch: 10] train_cost = 0.99408 eval_acc = 52.498 total_best = 52.498\n",
            "[Epoch: 12] train_cost = 0.91655 eval_acc = 55.586 total_best = 55.586\n",
            "[Epoch: 14] train_cost = 0.85471 eval_acc = 53.588 total_best = 55.586\n",
            "[Epoch: 16] train_cost = 0.78994 eval_acc = 56.312 total_best = 56.312\n",
            "[Epoch: 18] train_cost = 0.73045 eval_acc = 50.772 total_best = 56.312\n",
            "3번동안 accuracy 증가가 없어 18epcoh 학습 후 종료합니다.\n",
            "\n",
            "[Epoch: 2] train_cost = 1.0485 eval_acc = 39.782 total_best = 39.782\n",
            "[Epoch: 4] train_cost = 1.0482 eval_acc = 39.873 total_best = 39.873\n",
            "[Epoch: 6] train_cost = 1.0478 eval_acc = 39.873 total_best = 39.873\n",
            "[Epoch: 8] train_cost = 1.0472 eval_acc = 39.964 total_best = 39.964\n",
            "[Epoch: 10] train_cost = 1.0456 eval_acc = 39.873 total_best = 39.964\n",
            "[Epoch: 12] train_cost = 1.0398 eval_acc = 40.236 total_best = 40.236\n",
            "[Epoch: 14] train_cost = 1.0213 eval_acc = 42.961 total_best = 42.961\n",
            "[Epoch: 16] train_cost = 0.97917 eval_acc = 51.045 total_best = 51.045\n",
            "[Epoch: 18] train_cost = 0.93332 eval_acc = 50.681 total_best = 51.045\n",
            "3번동안 accuracy 증가가 없어 18epcoh 학습 후 종료합니다.\n",
            "\n",
            "[Epoch: 2] train_cost = 1.054 eval_acc = 39.51 total_best = 39.51\n",
            "[Epoch: 4] train_cost = 0.94354 eval_acc = 54.223 total_best = 54.223\n",
            "[Epoch: 6] train_cost = 0.76959 eval_acc = 58.038 total_best = 58.038\n",
            "[Epoch: 8] train_cost = 0.61587 eval_acc = 58.038 total_best = 58.038\n",
            "[Epoch: 10] train_cost = 0.44166 eval_acc = 54.95 total_best = 58.038\n",
            "[Epoch: 12] train_cost = 0.27956 eval_acc = 51.862 total_best = 58.038\n",
            "3번동안 accuracy 증가가 없어 12epcoh 학습 후 종료합니다.\n",
            "\n",
            "[Epoch: 2] train_cost = 1.0497 eval_acc = 39.964 total_best = 39.964\n",
            "[Epoch: 4] train_cost = 1.0484 eval_acc = 41.326 total_best = 41.326\n",
            "[Epoch: 6] train_cost = 1.0478 eval_acc = 38.147 total_best = 41.326\n",
            "[Epoch: 8] train_cost = 1.0475 eval_acc = 38.965 total_best = 41.326\n",
            "[Epoch: 10] train_cost = 1.0458 eval_acc = 40.145 total_best = 41.326\n",
            "3번동안 accuracy 증가가 없어 10epcoh 학습 후 종료합니다.\n",
            "\n",
            "[Epoch: 2] train_cost = 1.0486 eval_acc = 38.692 total_best = 38.692\n",
            "[Epoch: 4] train_cost = 1.0469 eval_acc = 39.964 total_best = 39.964\n",
            "[Epoch: 6] train_cost = 1.0474 eval_acc = 40.145 total_best = 40.145\n",
            "[Epoch: 8] train_cost = 1.0479 eval_acc = 40.236 total_best = 40.236\n",
            "[Epoch: 10] train_cost = 1.0468 eval_acc = 40.236 total_best = 40.236\n",
            "[Epoch: 12] train_cost = 1.0473 eval_acc = 40.236 total_best = 40.236\n",
            "[Epoch: 14] train_cost = 1.0457 eval_acc = 42.688 total_best = 42.688\n",
            "[Epoch: 16] train_cost = 1.0424 eval_acc = 42.416 total_best = 42.688\n",
            "3번동안 accuracy 증가가 없어 16epcoh 학습 후 종료합니다.\n",
            "\n",
            "[Epoch: 2] train_cost = 1.0474 eval_acc = 48.32 total_best = 48.32\n",
            "[Epoch: 4] train_cost = 0.90881 eval_acc = 57.947 total_best = 57.947\n",
            "[Epoch: 6] train_cost = 0.72485 eval_acc = 60.127 total_best = 60.127\n",
            "[Epoch: 8] train_cost = 0.55102 eval_acc = 59.401 total_best = 60.127\n",
            "[Epoch: 10] train_cost = 0.38422 eval_acc = 56.312 total_best = 60.127\n",
            "[Epoch: 12] train_cost = 0.24553 eval_acc = 53.678 total_best = 60.127\n",
            "3번동안 accuracy 증가가 없어 12epcoh 학습 후 종료합니다.\n",
            "\n",
            "[Epoch: 2] train_cost = 1.05 eval_acc = 40.145 total_best = 40.145\n",
            "[Epoch: 4] train_cost = 1.0478 eval_acc = 40.145 total_best = 40.145\n",
            "[Epoch: 6] train_cost = 1.0474 eval_acc = 40.418 total_best = 40.418\n",
            "[Epoch: 8] train_cost = 1.0396 eval_acc = 40.872 total_best = 40.872\n",
            "[Epoch: 10] train_cost = 0.97488 eval_acc = 53.951 total_best = 53.951\n",
            "[Epoch: 12] train_cost = 0.90747 eval_acc = 55.949 total_best = 55.949\n",
            "[Epoch: 14] train_cost = 0.84163 eval_acc = 55.223 total_best = 55.949\n",
            "[Epoch: 16] train_cost = 0.78524 eval_acc = 56.585 total_best = 56.585\n",
            "[Epoch: 18] train_cost = 0.71928 eval_acc = 55.586 total_best = 56.585\n",
            "3번동안 accuracy 증가가 없어 18epcoh 학습 후 종료합니다.\n",
            "\n",
            "[Epoch: 2] train_cost = 1.0497 eval_acc = 40.418 total_best = 40.418\n",
            "[Epoch: 4] train_cost = 1.0479 eval_acc = 40.327 total_best = 40.418\n",
            "[Epoch: 6] train_cost = 1.0481 eval_acc = 40.509 total_best = 40.509\n",
            "[Epoch: 8] train_cost = 1.0474 eval_acc = 40.418 total_best = 40.509\n",
            "[Epoch: 10] train_cost = 1.0477 eval_acc = 40.327 total_best = 40.509\n",
            "3번동안 accuracy 증가가 없어 10epcoh 학습 후 종료합니다.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = BasicGRU(1, 256, vocab_size, 128, n_classes, 0.5).to(device)\n",
        "model.load_state_dict(torch.load('/model_s1.pt')) # 가장 정확도가 높았던 모델 불러오기\n",
        "\n",
        "corrects = 0\n",
        "model.eval()\n",
        "for batch in test_iter:\n",
        "    x,y = batch.text.to(device), batch.label.to(device)\n",
        "    y.data.sub_(1)\n",
        "    hypothesis = model(x)\n",
        "    corrects += (hypothesis.max(1)[1].view(y.size()).data == y.data).sum()\n",
        "\n",
        "test_acc = corrects/len(test_iter.dataset)*100.0\n",
        "print(f'test_acc = {test_acc:>.9}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "An6gDl8Owa3J",
        "outputId": "19502cc8-f588-49fa-ae8f-4d2c3054baab"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_acc = 61.3122177\n"
          ]
        }
      ]
    }
  ]
}